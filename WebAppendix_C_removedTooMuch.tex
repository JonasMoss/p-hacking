\section*{Web Appendix C}

As mentioned in Section 2, any \textit{p}-hacking model can be written on the form of a selection model. Observe that
\begin{eqnarray*}
\int_{[0,1]}\phi_\alpha^{\star}(x_{i}\mid\theta_{i},\sigma_{i}^2)d\omega(\alpha) & = & \int_{[0,1]}\phi(x_{i}\mid\theta_{i}, \sigma_i^2)P(u_i\in\left[0,\alpha\right]\mid\theta_{i},\sigma^2_{i})^{-1}d\omega(\alpha)\\
 & = & \phi(x_{i}\mid\theta_{i}, \sigma^2_i)\int_{[0,u_i)}P(u_i\in\left[0,\alpha\right]\mid\theta_{i},\sigma_{i}^2)^{-1}d\omega(\alpha).
\end{eqnarray*}
where $\phi_\alpha^{\star}$ is a Gaussian density truncated so that the \textit{p}-value associated to $x_i$, $u_i$, lies in the interval $\left[0,\alpha\right)$. This is a publication bias model if $$h(u_i)=\int_{[0,u_i]}P(u_i\in\left[0,\alpha\right]\mid\theta_{i},\sigma^2_{i})^{-1}d\omega(\alpha)$$ is bounded for each $u_i$ and $h(u_i)$ is independent of $\theta_{i},\sigma^2_{i}$. While $h(u_i)$ can be bounded, it is typically dependent of $\theta_{i},\sigma^2_{i}$, with the fixed effect model under complete selection for significance being a notable exception.

On the other hand, any selection model with 
$$
I = \int \phi(x;\theta_{i},\sigma^2_{i})w(u_i)du_i<\infty
$$
can be written as a mixture model. For then there is a finite measure $d\omega(\alpha)$ satisfying 
\[
w(u_i)=\int_{[0,u_i)}\frac{1}{P(u_i\in\left[0,\alpha\right)\mid\theta_i,\sigma^2_{i})}d\omega(\alpha)
\]
Just take $d\omega(\alpha)=d w(\alpha)P(u_i\in\left[0,\alpha\right)\mid\theta_{i},\sigma^2_{i})$, where $d\rho(\alpha)$ is defined by $\int_{0}^{u_i}d w(\alpha)= w(u_i)$. The size of the measure is
\begin{eqnarray*}
\int_{0}^{1}d\omega(\alpha;\theta_{i},\sigma^2_{i}) & = & \int_{0}^{1}P(u_i\in\left[0,\alpha\right)\mid\theta_{i},\sigma^2_{i})d w(\alpha)\\
 & = & \int_{0}^{1}\phi(u_i;\theta_{i},\sigma^2_{i})\int_{0}^{u_i}d w(\alpha)du_i\\
 & = & I
\end{eqnarray*}
Hence $I d\omega'(\alpha;\theta_{i},\sigma^2_{i})$ is a probability measure. This probability measure makes 
\[
I^{-1}\phi(x_{i};\theta_{i},\sigma^2_{i})w(u_i)=\int_{[0,1]}\phi_\alpha(x_{i};\theta_{i},\sigma^2_{i})d\omega'(\alpha)
\]
as can be seen by the following computation,
\begin{eqnarray*}
I^{-1}\phi(x_{i};\theta_{i},\sigma^2_{i})w(u_i) & = & I^{-1}\int_{[0,u_i)}\frac{\phi(x_{i};\theta_{i},\sigma^2_{i})}{P(u_i\in\left[0,\alpha\right)\mid\theta_{i},\sigma^2_{i})}d\omega(\alpha)\\
 & = & I^{-1}\int_{[0,1]}\frac{\phi(x_{i};\theta,\sigma^2_{i})1_{\left[0,\alpha\right)}(u_i)}{P(u_i\in\left[0,\alpha\right)\mid\theta_{i},\sigma^2_{i})}d\omega(\alpha)\\
 & = & I^{-1}\int_{[0,1]}\phi_\alpha(x_{i};\theta_{i},\sigma^2_{i})d\omega(\alpha)\\
 & = & \int_{[0,1]}\phi_\alpha(x;\theta_{i},\sigma^2_{i})d\omega'(\alpha)
\end{eqnarray*}

Proposition 1 shows the form of the one-sided normal step function selection probability publication bias model when it is written as a mixture model of the form (5). But most such mixture models are not true \textit{p}-hacking models, as the mixing probabilities $\pi_{i}^{\star}$ depend on $\theta$. There is no way for the \textit{p}-hacker to know
$\theta$, so we cannot regard the publication bias model as a \textit{p}-hacking model.



